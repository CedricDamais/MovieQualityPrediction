{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMybqSDHNQa/CWZ9yvkYf49",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CedricDamais/MovieQualityPrediction/blob/main/MovieQualitiePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Qualitie Prediction Neural Network\n",
        "\n",
        "We will work with the Large Movie Review Dataset  It has a wide range of metadata, including cast, crew,\n",
        "plot keywords, budget, posters, release dates, languages, production companies, and countries in movie reviews. We\n",
        "have ratings from 0 to 10 for all films in the training data. Our goal is to build a model for predicting which movie\n",
        "will have higher ratings after analyzing the reviews with metadata.\n",
        "\n",
        "By predicting the ratings from 0 to 10, we can solve the regression problem. To do such a task since there is no\n",
        "difference between movies with ratings of 2.72 or 3.14 we will tag movies with ratings >7 as good and with movie ratings\n",
        "< 5 as \" bad\" other data isn't relevant. So the problem becomes a classification problem"
      ],
      "metadata": {
        "id": "xAliCU827oWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHcV3hoF5npa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Dataload():\n",
        "\n",
        "  if not os.path.exists('../Data'):\n",
        "    os.mkdir('../Data')\n",
        "\n",
        "  # Download data if it is unavailable.\n",
        "  if ('dataset.csv' not in os.listdir('../Data')):\n",
        "    print('Dataset loading.')\n",
        "    url = \"https://www.dropbox.com/s/0sj7tz08sgcbxmh/large_movie_review_dataset.csv?dl=1\"\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('../Data/dataset.csv', 'wb').write(r.content)\n",
        "    print('Loaded.')"
      ],
      "metadata": {
        "id": "pmbLH5sB7Hg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, target_col:str, X_col:str):\n",
        "  y = data[target_col]\n",
        "  X = data[X_col]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=23)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "wZ6PEjuR7IcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, X_train, y_train,\n",
        "              X_test,\n",
        "              y_test, model_name:str)-> None:\n",
        "\n",
        "  model.fit(X=X_train, y=y_train)\n",
        "  preds = model.predict(X_test)\n",
        "  pred_probs = model.predict_proba(X_test)\n",
        "  acc = accuracy_score(y_true=y_test, y_pred=preds)\n",
        "  AUC = roc_auc_score(y_true=y_test, y_score=pred_probs[:, 1])\n",
        "  print(f\"The accuracy score for {model_name} is : {acc}\")\n",
        "  print(f\"The AUC score for {model_name} is : {AUC}\")\n"
      ],
      "metadata": {
        "id": "dxQetPXw7IZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cons_features(model: sklearn.linear_model) -> int:\n",
        "    lst = []\n",
        "    for coef in model.coef_[0]:\n",
        "        if abs(coef) > 0.0001 and coef is not None:\n",
        "            lst.append(coef)\n",
        "    return len(lst)"
      ],
      "metadata": {
        "id": "Rp2Y6-gu7IX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dataload()\n",
        "df = pd.read_csv('../Data/dataset.csv')\n",
        "\n",
        "# Dropping all the movies with irrelevant data to us\n",
        "df.drop(df[(df['rating'] >= 5) & (df['rating'] <= 7)].index, inplace=True)\n",
        "\n",
        "# Adding binary column label\n",
        "# 1 if rating > 7 and 0 if rating < 5\n",
        "\n",
        "df['label'] = 0\n",
        "df.loc[df['rating'] > 7, \"label\"] = 1\n",
        "\n",
        "# We no longer need the rating column since we already have the binary col\n",
        "df.drop('rating', inplace=True, axis=1)\n",
        "good_movies_col = df['label'].value_counts()[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybBLHoli7IVf",
        "outputId": "5d1c5f74-b9b4-4a7b-a3db-6a09c423143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loading.\n",
            "Loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform our words into a feature matrix using the bag-of-words model\n",
        "\n",
        "# Split the data into training  and test samples\n",
        "X_train, X_test, y_train, y_test = split_data(data=df, target_col='label', X_col='review')\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
        "training_ft_matrix = vectorizer.fit_transform(X_train)\n",
        "tst_ft_matrix = vectorizer.transform(X_test)\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "print(f\"The amount of terms {len(terms)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyqixQnbCr1A",
        "outputId": "36e0f558-2baa-48cc-d4ef-a75bfa6a84cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of terms 66648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with the classification problem\n",
        "\n",
        "1. It's time to solve the classification problem using a logistic regression model\n",
        "2. We Will add two metrics to the model Accuracy and AUC ( Area under the curve )\n",
        "3. AUC is the measure of a classifier's ability to distinguish between classes\n",
        "4. predict_proba returns probabilities for each class.\n",
        "5. To calculate the AUC score you would need probabilities for class 1"
      ],
      "metadata": {
        "id": "kyicnYP5C_Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = LogisticRegression(solver='liblinear')\n",
        "make_predictions(model=model_0,\n",
        "                  X_train=training_ft_matrix,\n",
        "                  y_train=y_train,\n",
        "                  X_test=tst_ft_matrix,\n",
        "                  y_test=y_test, model_name='model_0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHbmtf2e7ITI",
        "outputId": "5966419f-425a-439f-9ac3-484f4d150d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score for model_0 is : 0.8896\n",
            "The AUC score for model_0 is : 0.9584481271304949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attempt to make my model perform better on this task\n",
        "\n",
        "- You can guess that there are a lot of extra words in our bag and a lot of extra features in our feature matrix do not improve the model's performance.\n",
        "\n",
        "\n",
        "- To find the extra features we will use the L1-regularization method. The L1-regularization sets coefficients of extra features to null, or sometimes near null\n"
      ],
      "metadata": {
        "id": "8vo_lD3214MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = LogisticRegression(solver='liblinear', penalty='l1', C=0.15)\n",
        "make_predictions(model=model_1,\n",
        "                X_train=training_ft_matrix,\n",
        "                X_test=tst_ft_matrix,\n",
        "                y_test=y_test,\n",
        "                y_train=y_train,\n",
        "                model_name='model_1')"
      ],
      "metadata": {
        "id": "c5RJSN-h7IQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb9e04b-4939-46da-84bb-470c994b2c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score for model_1 is : 0.81024\n",
            "The AUC score for model_1 is : 0.8910192132661898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "considered_feat_mod1 = round(get_cons_features(model_1), -2)\n",
        "considered_feat_mod0 = get_cons_features(model_0)\n",
        "print(f\"In model_1 considered features : {considered_feat_mod1}\")\n",
        "print(f\"In model_0 considered features : {considered_feat_mod0}\")"
      ],
      "metadata": {
        "id": "bL70yFWzC-CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438deb86-fa13-475b-d360-abe37b39d052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In model_1 considered features : 100\n",
            "In model_0 considered features : 66616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From Model_0 to model_1 we dropped in terms of accuracy and AUC of about 6%\n",
        "- But the amount of features in model_1 is considerably smaller compared to model_0\n"
      ],
      "metadata": {
        "id": "eyQqAiAH3VxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = LogisticRegression(solver='liblinear')\n",
        "SVD = TruncatedSVD(n_components=considered_feat_mod1)\n",
        "SVD_training_ft_matrix = SVD.fit_transform(training_ft_matrix)\n",
        "SVD_test_ft_matrix = SVD.transform(tst_ft_matrix)"
      ],
      "metadata": {
        "id": "yaJoXPNR3T4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions(model=model_2,\n",
        "                X_train=SVD_training_ft_matrix,\n",
        "                y_train=y_train,\n",
        "                X_test=SVD_test_ft_matrix,\n",
        "                y_test=y_test,\n",
        "                model_name='model_2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuDitRVf3T2A",
        "outputId": "0802a2eb-e22b-48ac-a791-b8431c4d2b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score for model_2 is : 0.86048\n",
            "The AUC score for model_2 is : 0.9383577789847681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KmaO-VhA3Trb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}